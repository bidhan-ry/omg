{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run time Main Execute with Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  coco\n",
      "Dataset:  /volumes/notebooks/Final IDV/samples/idvscript\n",
      "Logs:  /volumes/notebooks/Final IDV/logs\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.6\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           idv\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                30\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Downloading pretrained model to /volumes/notebooks/Final IDV/mask_rcnn_coco.h5 ...\n",
      "... done downloading pretrained model!\n",
      "Loading weights  /volumes/notebooks/Final IDV/mask_rcnn_coco.h5\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /volumes/notebooks/Final IDV/logs/idv20180623T0513/mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29/30 [============================>.] - ETA: 4s - loss: 2.1439 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.4055 - mrcnn_class_loss: 0.1868 - mrcnn_bbox_loss: 0.8988 - mrcnn_mask_loss: 0.6421 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 224s 7s/step - loss: 2.1198 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.3953 - mrcnn_class_loss: 0.1833 - mrcnn_bbox_loss: 0.8977 - mrcnn_mask_loss: 0.6328 - val_loss: 1.4583 - val_rpn_class_loss: 0.0085 - val_rpn_bbox_loss: 0.2573 - val_mrcnn_class_loss: 0.1451 - val_mrcnn_bbox_loss: 0.6686 - val_mrcnn_mask_loss: 0.3788\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 139s 5s/step - loss: 1.2820 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.1860 - mrcnn_class_loss: 0.1158 - mrcnn_bbox_loss: 0.6481 - mrcnn_mask_loss: 0.3254 - val_loss: 1.2812 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.2858 - val_mrcnn_class_loss: 0.1213 - val_mrcnn_bbox_loss: 0.5641 - val_mrcnn_mask_loss: 0.3019\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 139s 5s/step - loss: 1.3130 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.3521 - mrcnn_class_loss: 0.1116 - mrcnn_bbox_loss: 0.5240 - mrcnn_mask_loss: 0.3161 - val_loss: 1.0055 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.3215 - val_mrcnn_class_loss: 0.0660 - val_mrcnn_bbox_loss: 0.3363 - val_mrcnn_mask_loss: 0.2747\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 140s 5s/step - loss: 0.9356 - rpn_class_loss: 0.0078 - rpn_bbox_loss: 0.2382 - mrcnn_class_loss: 0.0803 - mrcnn_bbox_loss: 0.3639 - mrcnn_mask_loss: 0.2453 - val_loss: 1.0015 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.2467 - val_mrcnn_class_loss: 0.0927 - val_mrcnn_bbox_loss: 0.3447 - val_mrcnn_mask_loss: 0.3104\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 139s 5s/step - loss: 0.8991 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.2222 - mrcnn_class_loss: 0.0664 - mrcnn_bbox_loss: 0.3285 - mrcnn_mask_loss: 0.2762 - val_loss: 0.9359 - val_rpn_class_loss: 0.0068 - val_rpn_bbox_loss: 0.2501 - val_mrcnn_class_loss: 0.0581 - val_mrcnn_bbox_loss: 0.3483 - val_mrcnn_mask_loss: 0.2727\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 139s 5s/step - loss: 0.7623 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.1644 - mrcnn_class_loss: 0.0622 - mrcnn_bbox_loss: 0.3204 - mrcnn_mask_loss: 0.2096 - val_loss: 0.9304 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2339 - val_mrcnn_class_loss: 0.0550 - val_mrcnn_bbox_loss: 0.3470 - val_mrcnn_mask_loss: 0.2887\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.6979 - rpn_class_loss: 0.0041 - rpn_bbox_loss: 0.1324 - mrcnn_class_loss: 0.0557 - mrcnn_bbox_loss: 0.2858 - mrcnn_mask_loss: 0.2198 - val_loss: 0.8562 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.2303 - val_mrcnn_class_loss: 0.0674 - val_mrcnn_bbox_loss: 0.2891 - val_mrcnn_mask_loss: 0.2639\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.8123 - rpn_class_loss: 0.0046 - rpn_bbox_loss: 0.1920 - mrcnn_class_loss: 0.0744 - mrcnn_bbox_loss: 0.2790 - mrcnn_mask_loss: 0.2623 - val_loss: 0.8788 - val_rpn_class_loss: 0.0077 - val_rpn_bbox_loss: 0.2834 - val_mrcnn_class_loss: 0.0411 - val_mrcnn_bbox_loss: 0.2613 - val_mrcnn_mask_loss: 0.2852\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.9024 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.2614 - mrcnn_class_loss: 0.0754 - mrcnn_bbox_loss: 0.2839 - mrcnn_mask_loss: 0.2751 - val_loss: 0.8710 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.2214 - val_mrcnn_class_loss: 0.0686 - val_mrcnn_bbox_loss: 0.3084 - val_mrcnn_mask_loss: 0.2675\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.6788 - rpn_class_loss: 0.0042 - rpn_bbox_loss: 0.1335 - mrcnn_class_loss: 0.0654 - mrcnn_bbox_loss: 0.2470 - mrcnn_mask_loss: 0.2286 - val_loss: 0.7843 - val_rpn_class_loss: 0.0053 - val_rpn_bbox_loss: 0.2337 - val_mrcnn_class_loss: 0.0526 - val_mrcnn_bbox_loss: 0.2335 - val_mrcnn_mask_loss: 0.2592\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.7382 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.1998 - mrcnn_class_loss: 0.0669 - mrcnn_bbox_loss: 0.2404 - mrcnn_mask_loss: 0.2241 - val_loss: 0.8806 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.2461 - val_mrcnn_class_loss: 0.0443 - val_mrcnn_bbox_loss: 0.2961 - val_mrcnn_mask_loss: 0.2890\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.7174 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.1925 - mrcnn_class_loss: 0.0613 - mrcnn_bbox_loss: 0.2455 - mrcnn_mask_loss: 0.2123 - val_loss: 0.7998 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.1821 - val_mrcnn_class_loss: 0.0624 - val_mrcnn_bbox_loss: 0.2755 - val_mrcnn_mask_loss: 0.2755\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.6388 - rpn_class_loss: 0.0040 - rpn_bbox_loss: 0.1864 - mrcnn_class_loss: 0.0518 - mrcnn_bbox_loss: 0.1908 - mrcnn_mask_loss: 0.2059 - val_loss: 0.7768 - val_rpn_class_loss: 0.0031 - val_rpn_bbox_loss: 0.2175 - val_mrcnn_class_loss: 0.0540 - val_mrcnn_bbox_loss: 0.2328 - val_mrcnn_mask_loss: 0.2694\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.6148 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 0.1415 - mrcnn_class_loss: 0.0533 - mrcnn_bbox_loss: 0.2027 - mrcnn_mask_loss: 0.2122 - val_loss: 0.7827 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.1955 - val_mrcnn_class_loss: 0.0536 - val_mrcnn_bbox_loss: 0.2498 - val_mrcnn_mask_loss: 0.2788\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.7190 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.1988 - mrcnn_class_loss: 0.0593 - mrcnn_bbox_loss: 0.2198 - mrcnn_mask_loss: 0.2350 - val_loss: 0.7651 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.1670 - val_mrcnn_class_loss: 0.0651 - val_mrcnn_bbox_loss: 0.2404 - val_mrcnn_mask_loss: 0.2875\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.6263 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.1722 - mrcnn_class_loss: 0.0580 - mrcnn_bbox_loss: 0.1881 - mrcnn_mask_loss: 0.2041 - val_loss: 0.7256 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.1786 - val_mrcnn_class_loss: 0.0519 - val_mrcnn_bbox_loss: 0.2211 - val_mrcnn_mask_loss: 0.2705\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.6399 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.1498 - mrcnn_class_loss: 0.0522 - mrcnn_bbox_loss: 0.2113 - mrcnn_mask_loss: 0.2219 - val_loss: 0.6922 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.1699 - val_mrcnn_class_loss: 0.0475 - val_mrcnn_bbox_loss: 0.2225 - val_mrcnn_mask_loss: 0.2478\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.6300 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.1852 - mrcnn_class_loss: 0.0525 - mrcnn_bbox_loss: 0.1880 - mrcnn_mask_loss: 0.2000 - val_loss: 0.7834 - val_rpn_class_loss: 0.0049 - val_rpn_bbox_loss: 0.2022 - val_mrcnn_class_loss: 0.0621 - val_mrcnn_bbox_loss: 0.2426 - val_mrcnn_mask_loss: 0.2716\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.7072 - rpn_class_loss: 0.0048 - rpn_bbox_loss: 0.1834 - mrcnn_class_loss: 0.0629 - mrcnn_bbox_loss: 0.2180 - mrcnn_mask_loss: 0.2381 - val_loss: 0.7291 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.1866 - val_mrcnn_class_loss: 0.0505 - val_mrcnn_bbox_loss: 0.2231 - val_mrcnn_mask_loss: 0.2656\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 136s 5s/step - loss: 0.6821 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.2195 - mrcnn_class_loss: 0.0562 - mrcnn_bbox_loss: 0.1906 - mrcnn_mask_loss: 0.2098 - val_loss: 0.7502 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.1814 - val_mrcnn_class_loss: 0.0556 - val_mrcnn_bbox_loss: 0.2116 - val_mrcnn_mask_loss: 0.2974\n",
      "Training network All\n",
      "\n",
      "Starting at epoch 20. LR=0.001\n",
      "\n",
      "Checkpoint Path: /volumes/notebooks/Final IDV/logs/idv20180623T0513/mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "30/30 [==============================] - 212s 7s/step - loss: 0.5331 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.1272 - mrcnn_class_loss: 0.0615 - mrcnn_bbox_loss: 0.1469 - mrcnn_mask_loss: 0.1932 - val_loss: 0.6728 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.1755 - val_mrcnn_class_loss: 0.0531 - val_mrcnn_bbox_loss: 0.1994 - val_mrcnn_mask_loss: 0.2405\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 169s 6s/step - loss: 0.4774 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.1274 - mrcnn_class_loss: 0.0388 - mrcnn_bbox_loss: 0.1439 - mrcnn_mask_loss: 0.1638 - val_loss: 0.6566 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.1856 - val_mrcnn_class_loss: 0.0322 - val_mrcnn_bbox_loss: 0.1927 - val_mrcnn_mask_loss: 0.2428\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 168s 6s/step - loss: 0.6357 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.2457 - mrcnn_class_loss: 0.0429 - mrcnn_bbox_loss: 0.1617 - mrcnn_mask_loss: 0.1794 - val_loss: 0.6358 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.1459 - val_mrcnn_class_loss: 0.0440 - val_mrcnn_bbox_loss: 0.1777 - val_mrcnn_mask_loss: 0.2659\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 168s 6s/step - loss: 0.6001 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.1674 - mrcnn_class_loss: 0.0584 - mrcnn_bbox_loss: 0.1831 - mrcnn_mask_loss: 0.1875 - val_loss: 0.6666 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.1670 - val_mrcnn_class_loss: 0.0474 - val_mrcnn_bbox_loss: 0.2119 - val_mrcnn_mask_loss: 0.2360\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 169s 6s/step - loss: 0.5024 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.1130 - mrcnn_class_loss: 0.0451 - mrcnn_bbox_loss: 0.1533 - mrcnn_mask_loss: 0.1888 - val_loss: 0.6519 - val_rpn_class_loss: 0.0033 - val_rpn_bbox_loss: 0.2018 - val_mrcnn_class_loss: 0.0497 - val_mrcnn_bbox_loss: 0.1787 - val_mrcnn_mask_loss: 0.2183\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 169s 6s/step - loss: 0.4525 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.1036 - mrcnn_class_loss: 0.0393 - mrcnn_bbox_loss: 0.1195 - mrcnn_mask_loss: 0.1869 - val_loss: 0.5709 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.1186 - val_mrcnn_class_loss: 0.0423 - val_mrcnn_bbox_loss: 0.1682 - val_mrcnn_mask_loss: 0.2393\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 168s 6s/step - loss: 0.3811 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0837 - mrcnn_class_loss: 0.0370 - mrcnn_bbox_loss: 0.1108 - mrcnn_mask_loss: 0.1471 - val_loss: 0.6207 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.1301 - val_mrcnn_class_loss: 0.0562 - val_mrcnn_bbox_loss: 0.1880 - val_mrcnn_mask_loss: 0.2429\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 168s 6s/step - loss: 0.4230 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0822 - mrcnn_class_loss: 0.0312 - mrcnn_bbox_loss: 0.1296 - mrcnn_mask_loss: 0.1782 - val_loss: 0.6267 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.1821 - val_mrcnn_class_loss: 0.0386 - val_mrcnn_bbox_loss: 0.1633 - val_mrcnn_mask_loss: 0.2398\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 169s 6s/step - loss: 0.4894 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.1233 - mrcnn_class_loss: 0.0370 - mrcnn_bbox_loss: 0.1502 - mrcnn_mask_loss: 0.1768 - val_loss: 0.6043 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.1887 - val_mrcnn_class_loss: 0.0337 - val_mrcnn_bbox_loss: 0.1415 - val_mrcnn_mask_loss: 0.2377\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 169s 6s/step - loss: 0.3383 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0846 - mrcnn_class_loss: 0.0176 - mrcnn_bbox_loss: 0.0991 - mrcnn_mask_loss: 0.1355 - val_loss: 0.5559 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.1202 - val_mrcnn_class_loss: 0.0364 - val_mrcnn_bbox_loss: 0.1609 - val_mrcnn_mask_loss: 0.2359\n"
     ]
    }
   ],
   "source": [
    "%run -i main.py train --dataset='/volumes/notebooks/Final IDV/samples/idvscript' --weights=coco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
