{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report Without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "from samples.idvscript import main\n",
    "from samples import ivddataset\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\"\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.6\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           idv\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class IDVConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"idv\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 50\n",
    "    \n",
    "    #RPN_ANCHOR_SCALES = (4,8,32, 64, 128)\n",
    "    \n",
    "    # Loss weights for more precise optimization.\n",
    "    # Can be used for R-CNN training setup.\n",
    "    '''LOSS_WEIGHTS = {\n",
    "        \"rpn_class_loss\": 1.,\n",
    "        \"rpn_bbox_loss\": 1.,\n",
    "        \"mrcnn_class_loss\": 1.,\n",
    "        \"mrcnn_bbox_loss\": 1.,\n",
    "        \"mrcnn_mask_loss\": 1.\n",
    "    }'''\n",
    "\n",
    "    # Skip detections with < 60% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.6\n",
    "\n",
    "config = IDVConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# Load pretrained weights\n",
    "model_path = COCO_WEIGHTS_PATH\n",
    "model.load_weights(model_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "          \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "dataset_train = ivddataset.IDVDataset()\n",
    "dataset_train.load_idv(dataset_dir=os.path.join(\"train\"))\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ivddataset.IDVDataset()\n",
    "dataset_val.load_idv(dataset_dir=os.path.join(\"val\"))\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /volumes/notebooks/Final IDV/logs/idv20180622T1351/mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/50 [============================>.] - ETA: 2s - loss: 1.7194 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.2549 - mrcnn_class_loss: 0.2280 - mrcnn_bbox_loss: 0.6686 - mrcnn_mask_loss: 0.5617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 207s 4s/step - loss: 1.7004 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.2501 - mrcnn_class_loss: 0.2241 - mrcnn_bbox_loss: 0.6668 - mrcnn_mask_loss: 0.5533 - val_loss: 1.1845 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.2225 - val_mrcnn_class_loss: 0.1104 - val_mrcnn_bbox_loss: 0.4833 - val_mrcnn_mask_loss: 0.3575\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 186s 4s/step - loss: 0.9371 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.1639 - mrcnn_class_loss: 0.0773 - mrcnn_bbox_loss: 0.4125 - mrcnn_mask_loss: 0.2763 - val_loss: 0.9816 - val_rpn_class_loss: 0.0092 - val_rpn_bbox_loss: 0.2478 - val_mrcnn_class_loss: 0.0716 - val_mrcnn_bbox_loss: 0.3677 - val_mrcnn_mask_loss: 0.2853\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 185s 4s/step - loss: 0.7784 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.1571 - mrcnn_class_loss: 0.0531 - mrcnn_bbox_loss: 0.3009 - mrcnn_mask_loss: 0.2621 - val_loss: 0.9104 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.2268 - val_mrcnn_class_loss: 0.0586 - val_mrcnn_bbox_loss: 0.3410 - val_mrcnn_mask_loss: 0.2760\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 184s 4s/step - loss: 0.6567 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.1726 - mrcnn_class_loss: 0.0354 - mrcnn_bbox_loss: 0.2380 - mrcnn_mask_loss: 0.2055 - val_loss: 0.8723 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.2355 - val_mrcnn_class_loss: 0.0481 - val_mrcnn_bbox_loss: 0.2851 - val_mrcnn_mask_loss: 0.2976\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 185s 4s/step - loss: 0.6497 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.1399 - mrcnn_class_loss: 0.0491 - mrcnn_bbox_loss: 0.2336 - mrcnn_mask_loss: 0.2221 - val_loss: 0.9048 - val_rpn_class_loss: 0.0064 - val_rpn_bbox_loss: 0.2638 - val_mrcnn_class_loss: 0.0444 - val_mrcnn_bbox_loss: 0.2926 - val_mrcnn_mask_loss: 0.2975\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 184s 4s/step - loss: 0.5201 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.1023 - mrcnn_class_loss: 0.0408 - mrcnn_bbox_loss: 0.1759 - mrcnn_mask_loss: 0.1973 - val_loss: 0.8125 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.1935 - val_mrcnn_class_loss: 0.0552 - val_mrcnn_bbox_loss: 0.2771 - val_mrcnn_mask_loss: 0.2802\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 184s 4s/step - loss: 0.5564 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.1076 - mrcnn_class_loss: 0.0440 - mrcnn_bbox_loss: 0.1732 - mrcnn_mask_loss: 0.2272 - val_loss: 0.8867 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.2481 - val_mrcnn_class_loss: 0.0421 - val_mrcnn_bbox_loss: 0.2934 - val_mrcnn_mask_loss: 0.2970\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 182s 4s/step - loss: 0.4831 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.0908 - mrcnn_class_loss: 0.0458 - mrcnn_bbox_loss: 0.1611 - mrcnn_mask_loss: 0.1816 - val_loss: 0.8192 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.2049 - val_mrcnn_class_loss: 0.0547 - val_mrcnn_bbox_loss: 0.2556 - val_mrcnn_mask_loss: 0.2981\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 181s 4s/step - loss: 0.4280 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0911 - mrcnn_class_loss: 0.0384 - mrcnn_bbox_loss: 0.1275 - mrcnn_mask_loss: 0.1674 - val_loss: 0.8704 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.2176 - val_mrcnn_class_loss: 0.0551 - val_mrcnn_bbox_loss: 0.2737 - val_mrcnn_mask_loss: 0.3195\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 180s 4s/step - loss: 0.4938 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0874 - mrcnn_class_loss: 0.0508 - mrcnn_bbox_loss: 0.1409 - mrcnn_mask_loss: 0.2103 - val_loss: 0.8496 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.2111 - val_mrcnn_class_loss: 0.0557 - val_mrcnn_bbox_loss: 0.2596 - val_mrcnn_mask_loss: 0.3180\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 180s 4s/step - loss: 0.3931 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0763 - mrcnn_class_loss: 0.0404 - mrcnn_bbox_loss: 0.1087 - mrcnn_mask_loss: 0.1649 - val_loss: 0.7855 - val_rpn_class_loss: 0.0049 - val_rpn_bbox_loss: 0.2051 - val_mrcnn_class_loss: 0.0637 - val_mrcnn_bbox_loss: 0.2094 - val_mrcnn_mask_loss: 0.3024\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.4032 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0785 - mrcnn_class_loss: 0.0445 - mrcnn_bbox_loss: 0.1108 - mrcnn_mask_loss: 0.1669 - val_loss: 0.9076 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.2731 - val_mrcnn_class_loss: 0.0582 - val_mrcnn_bbox_loss: 0.2606 - val_mrcnn_mask_loss: 0.3096\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 0.4179 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0677 - mrcnn_class_loss: 0.0459 - mrcnn_bbox_loss: 0.1174 - mrcnn_mask_loss: 0.1835 - val_loss: 0.8534 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.2587 - val_mrcnn_class_loss: 0.0613 - val_mrcnn_bbox_loss: 0.2456 - val_mrcnn_mask_loss: 0.2827\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 0.4212 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0768 - mrcnn_class_loss: 0.0480 - mrcnn_bbox_loss: 0.1113 - mrcnn_mask_loss: 0.1820 - val_loss: 0.8156 - val_rpn_class_loss: 0.0042 - val_rpn_bbox_loss: 0.2132 - val_mrcnn_class_loss: 0.0792 - val_mrcnn_bbox_loss: 0.2229 - val_mrcnn_mask_loss: 0.2961\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 0.4026 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0598 - mrcnn_class_loss: 0.0524 - mrcnn_bbox_loss: 0.1083 - mrcnn_mask_loss: 0.1788 - val_loss: 0.8648 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.2392 - val_mrcnn_class_loss: 0.0708 - val_mrcnn_bbox_loss: 0.2595 - val_mrcnn_mask_loss: 0.2899\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.3885 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0583 - mrcnn_class_loss: 0.0532 - mrcnn_bbox_loss: 0.1082 - mrcnn_mask_loss: 0.1657 - val_loss: 0.7988 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2578 - val_mrcnn_class_loss: 0.0620 - val_mrcnn_bbox_loss: 0.2101 - val_mrcnn_mask_loss: 0.2632\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 0.3455 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0474 - mrcnn_class_loss: 0.0464 - mrcnn_bbox_loss: 0.0834 - mrcnn_mask_loss: 0.1656 - val_loss: 0.7644 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.1999 - val_mrcnn_class_loss: 0.0618 - val_mrcnn_bbox_loss: 0.2004 - val_mrcnn_mask_loss: 0.2968\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.3329 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0556 - mrcnn_class_loss: 0.0430 - mrcnn_bbox_loss: 0.0903 - mrcnn_mask_loss: 0.1411 - val_loss: 0.7945 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2040 - val_mrcnn_class_loss: 0.0646 - val_mrcnn_bbox_loss: 0.2145 - val_mrcnn_mask_loss: 0.3071\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 0.3305 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0613 - mrcnn_class_loss: 0.0427 - mrcnn_bbox_loss: 0.0777 - mrcnn_mask_loss: 0.1463 - val_loss: 0.8027 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2046 - val_mrcnn_class_loss: 0.0678 - val_mrcnn_bbox_loss: 0.2206 - val_mrcnn_mask_loss: 0.3040\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.3068 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0439 - mrcnn_class_loss: 0.0355 - mrcnn_bbox_loss: 0.0688 - mrcnn_mask_loss: 0.1559 - val_loss: 0.7692 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.2115 - val_mrcnn_class_loss: 0.0546 - val_mrcnn_bbox_loss: 0.2007 - val_mrcnn_mask_loss: 0.2971\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.3227 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0440 - mrcnn_class_loss: 0.0351 - mrcnn_bbox_loss: 0.0715 - mrcnn_mask_loss: 0.1688 - val_loss: 0.8120 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2259 - val_mrcnn_class_loss: 0.0514 - val_mrcnn_bbox_loss: 0.1982 - val_mrcnn_mask_loss: 0.3321\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2813 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0453 - mrcnn_class_loss: 0.0272 - mrcnn_bbox_loss: 0.0654 - mrcnn_mask_loss: 0.1407 - val_loss: 0.8067 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.1840 - val_mrcnn_class_loss: 0.0578 - val_mrcnn_bbox_loss: 0.2145 - val_mrcnn_mask_loss: 0.3463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2693 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.0316 - mrcnn_class_loss: 0.0321 - mrcnn_bbox_loss: 0.0653 - mrcnn_mask_loss: 0.1364 - val_loss: 0.7496 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.1844 - val_mrcnn_class_loss: 0.0627 - val_mrcnn_bbox_loss: 0.2016 - val_mrcnn_mask_loss: 0.2966\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2870 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0384 - mrcnn_class_loss: 0.0283 - mrcnn_bbox_loss: 0.0704 - mrcnn_mask_loss: 0.1476 - val_loss: 0.7875 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.2269 - val_mrcnn_class_loss: 0.0517 - val_mrcnn_bbox_loss: 0.1929 - val_mrcnn_mask_loss: 0.3115\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2730 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0347 - mrcnn_class_loss: 0.0297 - mrcnn_bbox_loss: 0.0642 - mrcnn_mask_loss: 0.1418 - val_loss: 0.7367 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.2111 - val_mrcnn_class_loss: 0.0535 - val_mrcnn_bbox_loss: 0.1893 - val_mrcnn_mask_loss: 0.2777\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2787 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0383 - mrcnn_class_loss: 0.0294 - mrcnn_bbox_loss: 0.0689 - mrcnn_mask_loss: 0.1395 - val_loss: 0.7910 - val_rpn_class_loss: 0.0042 - val_rpn_bbox_loss: 0.2088 - val_mrcnn_class_loss: 0.0559 - val_mrcnn_bbox_loss: 0.2307 - val_mrcnn_mask_loss: 0.2914\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.2749 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0339 - mrcnn_class_loss: 0.0313 - mrcnn_bbox_loss: 0.0714 - mrcnn_mask_loss: 0.1357 - val_loss: 0.7683 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.2258 - val_mrcnn_class_loss: 0.0657 - val_mrcnn_bbox_loss: 0.1793 - val_mrcnn_mask_loss: 0.2937\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2627 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0301 - mrcnn_class_loss: 0.0303 - mrcnn_bbox_loss: 0.0704 - mrcnn_mask_loss: 0.1294 - val_loss: 0.7354 - val_rpn_class_loss: 0.0040 - val_rpn_bbox_loss: 0.2102 - val_mrcnn_class_loss: 0.0529 - val_mrcnn_bbox_loss: 0.1881 - val_mrcnn_mask_loss: 0.2800\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 179s 4s/step - loss: 0.2554 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0336 - mrcnn_class_loss: 0.0279 - mrcnn_bbox_loss: 0.0626 - mrcnn_mask_loss: 0.1289 - val_loss: 0.8167 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.2741 - val_mrcnn_class_loss: 0.0501 - val_mrcnn_bbox_loss: 0.1994 - val_mrcnn_mask_loss: 0.2871\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.2879 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0530 - mrcnn_class_loss: 0.0340 - mrcnn_bbox_loss: 0.0658 - mrcnn_mask_loss: 0.1327 - val_loss: 0.8069 - val_rpn_class_loss: 0.0042 - val_rpn_bbox_loss: 0.2138 - val_mrcnn_class_loss: 0.0610 - val_mrcnn_bbox_loss: 0.1871 - val_mrcnn_mask_loss: 0.3408\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 30. LR=0.001\n",
      "\n",
      "Checkpoint Path: /volumes/notebooks/Final IDV/logs/idv20180622T1351/mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "50/50 [==============================] - 250s 5s/step - loss: 0.2805 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0552 - mrcnn_class_loss: 0.0371 - mrcnn_bbox_loss: 0.0720 - mrcnn_mask_loss: 0.1136 - val_loss: 0.7781 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.1451 - val_mrcnn_class_loss: 0.0949 - val_mrcnn_bbox_loss: 0.2178 - val_mrcnn_mask_loss: 0.3180\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 212s 4s/step - loss: 0.3318 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0844 - mrcnn_class_loss: 0.0368 - mrcnn_bbox_loss: 0.0805 - mrcnn_mask_loss: 0.1272 - val_loss: 0.7035 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1518 - val_mrcnn_class_loss: 0.0627 - val_mrcnn_bbox_loss: 0.1729 - val_mrcnn_mask_loss: 0.3135\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 213s 4s/step - loss: 0.3043 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0635 - mrcnn_class_loss: 0.0327 - mrcnn_bbox_loss: 0.0695 - mrcnn_mask_loss: 0.1363 - val_loss: 0.7211 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.2068 - val_mrcnn_class_loss: 0.0448 - val_mrcnn_bbox_loss: 0.2024 - val_mrcnn_mask_loss: 0.2643\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 212s 4s/step - loss: 0.2759 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0533 - mrcnn_class_loss: 0.0310 - mrcnn_bbox_loss: 0.0684 - mrcnn_mask_loss: 0.1211 - val_loss: 0.7147 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.1630 - val_mrcnn_class_loss: 0.0610 - val_mrcnn_bbox_loss: 0.1936 - val_mrcnn_mask_loss: 0.2948\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 212s 4s/step - loss: 0.2663 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0555 - mrcnn_class_loss: 0.0229 - mrcnn_bbox_loss: 0.0665 - mrcnn_mask_loss: 0.1198 - val_loss: 0.5754 - val_rpn_class_loss: 0.0017 - val_rpn_bbox_loss: 0.1526 - val_mrcnn_class_loss: 0.0424 - val_mrcnn_bbox_loss: 0.1423 - val_mrcnn_mask_loss: 0.2363\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 213s 4s/step - loss: 0.2588 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0480 - mrcnn_class_loss: 0.0258 - mrcnn_bbox_loss: 0.0632 - mrcnn_mask_loss: 0.1198 - val_loss: 0.6520 - val_rpn_class_loss: 0.0023 - val_rpn_bbox_loss: 0.1980 - val_mrcnn_class_loss: 0.0519 - val_mrcnn_bbox_loss: 0.1501 - val_mrcnn_mask_loss: 0.2498\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 214s 4s/step - loss: 0.1927 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0329 - mrcnn_class_loss: 0.0180 - mrcnn_bbox_loss: 0.0470 - mrcnn_mask_loss: 0.0928 - val_loss: 0.6119 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1325 - val_mrcnn_class_loss: 0.0440 - val_mrcnn_bbox_loss: 0.1761 - val_mrcnn_mask_loss: 0.2566\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 213s 4s/step - loss: 0.1961 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0364 - mrcnn_class_loss: 0.0139 - mrcnn_bbox_loss: 0.0459 - mrcnn_mask_loss: 0.0989 - val_loss: 0.5474 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.1312 - val_mrcnn_class_loss: 0.0419 - val_mrcnn_bbox_loss: 0.1331 - val_mrcnn_mask_loss: 0.2387\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 213s 4s/step - loss: 0.2243 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0403 - mrcnn_class_loss: 0.0207 - mrcnn_bbox_loss: 0.0469 - mrcnn_mask_loss: 0.1147 - val_loss: 0.5535 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.1033 - val_mrcnn_class_loss: 0.0457 - val_mrcnn_bbox_loss: 0.1523 - val_mrcnn_mask_loss: 0.2493\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 213s 4s/step - loss: 0.1947 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0360 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 0.0425 - mrcnn_mask_loss: 0.0956 - val_loss: 0.6457 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1533 - val_mrcnn_class_loss: 0.0498 - val_mrcnn_bbox_loss: 0.1627 - val_mrcnn_mask_loss: 0.2771\n",
      "Fine tune all layers\n",
      "\n",
      "Starting at epoch 40. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /volumes/notebooks/Final IDV/logs/idv20180622T1351/mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "50/50 [==============================] - 276s 6s/step - loss: 0.1681 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0239 - mrcnn_class_loss: 0.0157 - mrcnn_bbox_loss: 0.0317 - mrcnn_mask_loss: 0.0948 - val_loss: 0.6019 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1417 - val_mrcnn_class_loss: 0.0385 - val_mrcnn_bbox_loss: 0.1475 - val_mrcnn_mask_loss: 0.2715\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 236s 5s/step - loss: 0.1354 - rpn_class_loss: 9.0348e-04 - rpn_bbox_loss: 0.0143 - mrcnn_class_loss: 0.0108 - mrcnn_bbox_loss: 0.0235 - mrcnn_mask_loss: 0.0858 - val_loss: 0.6294 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.1524 - val_mrcnn_class_loss: 0.0435 - val_mrcnn_bbox_loss: 0.1458 - val_mrcnn_mask_loss: 0.2852\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 235s 5s/step - loss: 0.1310 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0157 - mrcnn_class_loss: 0.0128 - mrcnn_bbox_loss: 0.0223 - mrcnn_mask_loss: 0.0791 - val_loss: 0.6268 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.1408 - val_mrcnn_class_loss: 0.0396 - val_mrcnn_bbox_loss: 0.1592 - val_mrcnn_mask_loss: 0.2845\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 236s 5s/step - loss: 0.1399 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0184 - mrcnn_class_loss: 0.0124 - mrcnn_bbox_loss: 0.0210 - mrcnn_mask_loss: 0.0867 - val_loss: 0.5419 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1091 - val_mrcnn_class_loss: 0.0431 - val_mrcnn_bbox_loss: 0.1296 - val_mrcnn_mask_loss: 0.2574\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 236s 5s/step - loss: 0.1332 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0112 - mrcnn_class_loss: 0.0140 - mrcnn_bbox_loss: 0.0195 - mrcnn_mask_loss: 0.0869 - val_loss: 0.6450 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.1420 - val_mrcnn_class_loss: 0.0475 - val_mrcnn_bbox_loss: 0.1556 - val_mrcnn_mask_loss: 0.2969\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 236s 5s/step - loss: 0.1053 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0066 - mrcnn_class_loss: 0.0097 - mrcnn_bbox_loss: 0.0130 - mrcnn_mask_loss: 0.0748 - val_loss: 0.5842 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.1180 - val_mrcnn_class_loss: 0.0458 - val_mrcnn_bbox_loss: 0.1428 - val_mrcnn_mask_loss: 0.2752\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 237s 5s/step - loss: 0.1110 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0068 - mrcnn_class_loss: 0.0119 - mrcnn_bbox_loss: 0.0156 - mrcnn_mask_loss: 0.0755 - val_loss: 0.6113 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.1272 - val_mrcnn_class_loss: 0.0422 - val_mrcnn_bbox_loss: 0.1432 - val_mrcnn_mask_loss: 0.2958\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 237s 5s/step - loss: 0.1236 - rpn_class_loss: 8.1471e-04 - rpn_bbox_loss: 0.0073 - mrcnn_class_loss: 0.0132 - mrcnn_bbox_loss: 0.0157 - mrcnn_mask_loss: 0.0865 - val_loss: 0.6333 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.1424 - val_mrcnn_class_loss: 0.0478 - val_mrcnn_bbox_loss: 0.1524 - val_mrcnn_mask_loss: 0.2877\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 238s 5s/step - loss: 0.1144 - rpn_class_loss: 9.7917e-04 - rpn_bbox_loss: 0.0075 - mrcnn_class_loss: 0.0108 - mrcnn_bbox_loss: 0.0130 - mrcnn_mask_loss: 0.0820 - val_loss: 0.6343 - val_rpn_class_loss: 0.0030 - val_rpn_bbox_loss: 0.1247 - val_mrcnn_class_loss: 0.0469 - val_mrcnn_bbox_loss: 0.1493 - val_mrcnn_mask_loss: 0.3104\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 239s 5s/step - loss: 0.1266 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0077 - mrcnn_class_loss: 0.0147 - mrcnn_bbox_loss: 0.0155 - mrcnn_mask_loss: 0.0870 - val_loss: 0.5941 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.1213 - val_mrcnn_class_loss: 0.0427 - val_mrcnn_bbox_loss: 0.1427 - val_mrcnn_mask_loss: 0.2846\n"
     ]
    }
   ],
   "source": [
    "# *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "# Training - Stage 1\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train,dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='heads')\n",
    "\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train,dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=40,\n",
    "            layers='4+')\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train,dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=50,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
